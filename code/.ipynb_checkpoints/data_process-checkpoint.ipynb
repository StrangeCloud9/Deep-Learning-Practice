{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix = \"../data/\"\n",
    "train_data = data_prefix+\"train.npy\"\n",
    "train_labels = data_prefix+\"train_labels.npy\"\n",
    "valid_data = data_prefix+\"dev.npy\"\n",
    "valid_labels = data_prefix+\"dev_labels.npy\"\n",
    "test_data = data_prefix+\"test.npy\"\n",
    "test_labels = data_prefix+\"test_labels.npy\"\n",
    "\n",
    "model = \"../model/model_dict.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "paths.train_data = train_data\n",
    "paths.train_labels = train_labels\n",
    "if mode == \"train\":\n",
    "    data_path = paths.train_data\n",
    "    labels_path = paths.train_labels\n",
    "    shuffle = True\n",
    "if mode == \"val\":\n",
    "    data_path = paths.valid_data\n",
    "    labels_path = paths.valid_labels\n",
    "    shuffle = False\n",
    "if mode == \"test\":\n",
    "    data_path = paths.test_data\n",
    "    labels_path = None\n",
    "    shuffle = False\n",
    "data = np.load(data_path)\n",
    "if config.sanity:\n",
    "    data = data[:150]\n",
    "\n",
    "#padding the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 477 40\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print (len(data), len(data[0]), len(data[0][0]))\n",
    "print (type(data), type(data[0]), type(data[0][0]), type(data[0][0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,) (150,) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(3, 3, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b89917d4de5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "if labels_path:\n",
    "    labels = np.load(labels_path)\n",
    "    if config.sanity:\n",
    "        labels = labels[:150]\n",
    "\n",
    "    print(data.shape, labels.shape, type(data), type(labels), )\n",
    "    tmp = np.zeros(3 * 3 * 3 ).reshape((3, 3, 3))\n",
    "    print (tmp.shape)\n",
    "    print (type(tmp))\n",
    "    tmp = torch.from_numpy(tmp).type(torch.float32)\n",
    "    labels = torch.from_numpy(labels).type(torch.LongTensor)\n",
    "print (len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((9, 9))\n",
    "print (a)\n",
    "print (np.pad(a, ((2, 3), (1, 1)), 'constant', constant_values=1))\n",
    "a = a.reshape(-1)\n",
    "print (a.reshape(-1))\n",
    "a = np.array(a)\n",
    "print (a)\n",
    "a = np.array(a)\n",
    "print (len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import mlpmodel\n",
    "import routine\n",
    "import config\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print (config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (2,)\n",
      "(2,) (2,)\n"
     ]
    }
   ],
   "source": [
    "train_loader = data.get_loader(\"train\")\n",
    "val_loader = data.get_loader(\"val\")\n",
    "test_loader = data.get_loader(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.load_model:\n",
    "    model = mlpmodel.MLP.load()\n",
    "else:\n",
    "    model = mlpmodel.MLP(config.input_size, config.hidden_size, config.output_size, config.CUDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([32, 1000]) torch.Size([32])\n",
      "torch.Size([23, 1000]) torch.Size([23])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print (x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "Epoch 1\n",
      "Training loss : 4.051818485917716\n",
      "Validation loss : 4.569168213340971\n",
      "Epoch 2\n",
      "Training loss : 3.46747061301922\n",
      "Validation loss : 4.573770377371046\n",
      "Epoch 3\n",
      "Training loss : 3.275961029118505\n",
      "Validation loss : 4.479884841375881\n",
      "Epoch 4\n",
      "Training loss : 3.274281353786074\n",
      "Validation loss : 4.838169356187184\n",
      "Epoch 5\n",
      "Training loss : 3.1989311103163094\n",
      "Validation loss : 4.645611759689119\n",
      "Epoch 6\n",
      "Training loss : 3.0619563316476754\n",
      "Validation loss : 4.677780780527327\n",
      "Early stopping !\n"
     ]
    }
   ],
   "source": [
    "routine.train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-949ac8f1bbba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/course/deep_learning/hwp2/start_code/code/routine.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 1)"
     ]
    }
   ],
   "source": [
    "test_outputs = routine.predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
